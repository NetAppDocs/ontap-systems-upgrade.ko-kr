---
sidebar: sidebar 
permalink: upgrade-arl-auto/relocate_non_root_aggr_and_nas_data_lifs_node1_node2.html 
keywords: relocate, non-root, aggregates, nas, lif, node2, node3 
summary: '을 사용하여 ONTAP 9.5를 실행하는 컨트롤러를 업그레이드할 때 노드 1에서 노드 2로 비루트 애그리게이트 및 NAS 데이터 LIF를 이동하고 노드 1의 리소스를 노드 3으로 이동합니다 `system controller replace` 명령.' 
---
= 노드 1이 소유한 루트 이외의 Aggregate 및 NAS 데이터 LIF를 노드 2로 재배치합니다
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
노드 1을 노드 3으로 교체하려면 먼저 노드 1에서 노드 2로 루트 이외의 애그리게이트 및 NAS 데이터 LIF를 이동한 다음 노드 1의 리소스를 노드 3으로 이동해야 합니다.

.시작하기 전에
작업을 시작할 때 작업이 이미 일시 중지되어 있어야 합니다. 작업을 수동으로 다시 시작해야 합니다.

.이 작업에 대해
원격 LIF는 업그레이드 절차 중에 SAN LUN의 트래픽을 처리합니다. 업그레이드 중에 클러스터 또는 서비스 상태를 위해 SAN LIF를 이동할 필요가 없습니다. 노드 3을 온라인으로 설정한 후 LIF가 정상 작동하는지 확인해야 합니다.


NOTE: Aggregate 및 LIF의 홈 소유자는 수정되지 않으며 현재 소유자만 수정됩니다.

.단계
. 애그리게이트 재배치 및 NAS 데이터 LIF 이동 작업 재개:
+
`system controller replace resume`

+
루트 이외의 모든 애그리게이트 및 NAS 데이터 LIF는 노드 1에서 노드 2로 마이그레이션됩니다.

+
이 작업을 일시 중지하여 모든 노드1 비루트 애그리게이트 및 비 SAN 데이터 LIF가 노드 2로 마이그레이션되었는지 여부를 확인할 수 있도록 합니다.

. 애그리게이트 재배치 및 NAS 데이터 LIF 이동 작업의 상태를 확인합니다.
+
`system controller replace show-details`

. 작업이 여전히 일시 중지된 상태에서 루트가 아닌 모든 애그리게이트가 노드 2의 해당 상태에 대해 온라인 상태인지 확인합니다.
+
`storage aggregate show -node _node2_ -state online -root false`

+
다음 예제에서는 노드 2의 루트 이외의 애그리게이트가 온라인 상태인 것을 보여 줍니다.

+
[listing]
----
cluster::> storage aggregate show -node node2 -state online -root false

Aggregate  Size     Available  Used%  State  #Vols  Nodes  RAID Status
---------  -------  ---------  -----  ------ -----  ------ --------------
aggr_1     744.9GB  744.8GB    0%     online     5  node2  raid_dp,normal
aggr_2     825.0GB  825.0GB    0%     online     1  node2  raid_dp,normal
2 entries were displayed.
----
+
노드 2에서 애그리게이트가 오프라인 상태가 되거나 외부 상태가 된 경우, 각 애그리게이트에 대해 노드 2의 다음 명령을 사용하여 온라인 상태로 전환합니다.

+
`storage aggregate online -aggregate _aggr_name_`

. node2에서 다음 명령을 사용하고 해당 출력을 검사하여 node2에서 모든 볼륨이 온라인 상태인지 확인합니다.
+
`volume show -node _node2_ -state offline`

+
노드 2에 오프라인 볼륨이 있는 경우 각 볼륨에 대해 한 번씩 노드 2에서 다음 명령을 사용하여 온라인으로 전환합니다.

+
`volume online -vserver _vserver_name_ -volume _volume_name_`

+
를 클릭합니다 `_vserver_name_` 이 명령과 함께 사용하려면 이전 의 출력에서 찾을 수 있습니다 `volume show` 명령.



. [[step5]] 현재 데이터 LIF를 호스팅하는 포트가 새 하드웨어에 없으면 브로드캐스트 도메인에서 제거합니다.
+
`network port broadcast-domain remove-ports`

. LIF가 하나라도 다운되면 LIF의 관리 상태를 로 설정합니다 `up` 다음 명령을 각 LIF에 대해 한 번 입력합니다.
+
`network interface modify -vserver _vserver_name_ -lif _LIF_name_-home-node _nodename_ -status-admin up`

. 인터페이스 그룹 또는 VLAN이 구성되어 있는 경우 다음 하위 단계를 완료합니다.
+
.. VLAN 및 인터페이스 그룹 정보를 아직 저장하지 않은 경우, 노드 3을 부팅한 후 노드 3에서 VLAN 및 인터페이스 그룹을 다시 생성할 수 있도록 VLAN 및 인터페이스 그룹 정보를 기록합니다.
.. 인터페이스 그룹에서 VLAN을 제거합니다.
+
`network port vlan delete -node _nodename_ -port _ifgrp_ -vlan-id _VLAN_ID_`

+

NOTE: 수정 조치에 따라 vlan delete 명령에서 제안하는 오류를 해결하십시오.

.. 다음 명령을 입력하고 해당 출력을 검사하여 노드에 구성된 인터페이스 그룹이 있는지 확인합니다.
+
`network port ifgrp show -node _nodename_ -ifgrp _ifgrp_name_ -instance`

+
다음 예에서와 같이 노드에 대한 인터페이스 그룹 정보가 표시됩니다.

+
[listing]
----
cluster::> network port ifgrp show -node node1 -ifgrp a0a -instance
                 Node: node1
 Interface Group Name: a0a
Distribution Function: ip
        Create Policy: multimode_lacp
          MAC Address: 02:a0:98:17:dc:d4
   Port Participation: partial
        Network Ports: e2c, e2d
             Up Ports: e2c
           Down Ports: e2d
----
.. 노드에 인터페이스 그룹이 구성되어 있는 경우 해당 그룹 및 그룹에 할당된 포트의 이름을 기록한 다음 각 포트에 대해 다음 명령을 한 번 입력하여 포트를 삭제합니다.
+
`network port ifgrp remove-port -node _nodename_ -ifgrp _ifgrp_name_ -port _netport_`




